# -*- coding: utf-8 -*-
"""Predicting_Breast_Cancer_in_a_patient_using_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U9aVJ9XSmAe73HfNeeNeUD2xBQFcgO28
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import precision_score, recall_score, confusion_matrix, precision_recall_fscore_support
from sklearn.metrics import roc_auc_score,auc,f1_score
from sklearn.metrics import precision_recall_curve,roc_curve

df=pd.read_csv("/content/cancer.csv")
df

df['diagnosis'].value_counts()

df.head()

df.columns

df.shape

df.info()

df.describe().T

df.isnull().sum()

plt.figure(figsize=(20,10))
sns.heatmap(df.corr(),annot=True)
plt.ioff()

palette ={'B' : 'lightblue', 'M' : 'magenta'}
fig = plt.figure(figsize=(12,12))
def plot_scatter(a,b,k):
    plt.subplot(k)
    sns.scatterplot(x = df[a], y = df[b], hue = "diagnosis",
                    data = df, palette = palette)
    plt.title(a + ' vs ' + b,fontsize=15)

plot_scatter('texture_mean','texture_worst',221)
plot_scatter('area_mean','radius_worst',222)
plot_scatter('perimeter_mean','radius_worst',223)
plot_scatter('perimeter_mean','radius_worst',224)
plt.show()

fig = plt.figure(figsize=(12,12))
plot_scatter('smoothness_mean','texture_mean',221)
plot_scatter('texture_mean','symmetry_se',222)
plot_scatter('fractal_dimension_worst','texture_mean',223)
plot_scatter('texture_mean','symmetry_mean',224)
plt.show()

fig = plt.figure(figsize=(12,12))
plot_scatter('area_mean','fractal_dimension_mean',221)
plot_scatter('radius_mean','fractal_dimension_mean',222)
plot_scatter('area_mean','smoothness_se',223)
plot_scatter('smoothness_se','perimeter_mean',224)
plt.show()

from pylab import rcParams
rcParams['figure.figsize'] = 8,5
cols = ['radius_mean', 'texture_mean', 'perimeter_mean',
       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean','diagnosis']
sns_plot = sns.pairplot(data=df[cols],hue='diagnosis', palette='bwr')
plt.show()

sns.scatterplot(x= 'area_mean', y= 'smoothness_mean', hue= 'diagnosis', data=df, palette='CMRmap')
plt.show()

size = len(df['texture_mean'])
area = np.pi * (15 * np.random.rand( size ))**2
colors = np.random.rand( size )
plt.xlabel("texture mean")
plt.ylabel("radius mean")
plt.scatter(df['texture_mean'], df['radius_mean'], s=area, c= colors, alpha=0.5)
plt.show()

m = plt.hist(df[df["diagnosis"] == "M"].radius_mean,bins=30,fc = (1,0,0,0.5),label = "Malignant")
b = plt.hist(df[df["diagnosis"] == "B"].radius_mean,bins=30, fc = (1,0,0.5), label= "Bening")
plt.legend()
plt.xlabel ("Radius Mean Values")
plt.ylabel ("Frequency")
plt.title("Histogram of Radius Mean for Bening and Malignant Tumors")
plt.show()

sns.jointplot(data= df, x='area_mean', y='smoothness_mean', size=5)
plt.show()

LEncoder = LabelEncoder()
df['diagnosis'] = LEncoder.fit_transform(df['diagnosis'])

X = df.drop('diagnosis',axis=1).values
y = df['diagnosis'].values
df

random_state = 42
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=random_state)

sc = StandardScaler()
X_train = sc.fit_transform(x_train)
X_test= sc.transform(x_test)

logreg= LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)

GB = GradientBoostingClassifier()
GB.fit(X_train, y_train)
y_pred_GB = GB.predict(X_test)

RF = RandomForestClassifier()
RF.fit(X_train, y_train)
y_pred_RF = RF.predict(X_test)

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

XGB = XGBClassifier()
XGB.fit(X_train, y_train)
y_pred_XGB = XGB.predict(X_test)

svc = SVC(probability=True)
svc.fit(X_train,y_train)
y_pred_svc = svc.predict(X_test)

X_train.shape, y_train.shape,X_test.shape, y_test.shape

models = []
Z = [SVC() , DecisionTreeClassifier() , LogisticRegression() , KNeighborsClassifier() ,XGBClassifier(),
    RandomForestClassifier() , GradientBoostingClassifier()]
X = ["SVC" , "DecisionTreeClassifier" , "LogisticRegression" , "KNeighborsClassifier" ,
    "RandomForestClassifier" , "GradientBoostingClassifier", "XGB"]
for i in range(0,len(Z)):
    model = Z[i]
    model.fit( X_train , y_train )
    pred = model.predict(X_test)
    models.append(accuracy_score(pred , y_test))

d = { "Accuracy" : models , "Algorithm" : X }
df = pd.DataFrame(d)
df

sns.barplot(df['Accuracy'],df['Algorithm'],palette= "husl").set_title('Accuracy of all Algorithms')

sns.barplot(df['Accuracy'],df['Algorithm'],palette= "husl").set_title('Accuracy of all Algorithms')

xm = np.array(confusion_matrix(y_test, y_pred_svc, labels=[1,0]))
confusion_mat= pd.DataFrame(cm, index = ['cancer', 'healthy'],
                           columns =['predicted_cancer','predicted_healthy'])
confusion_mat

def xm():
  sns.heatmap(xm,annot=True,fmt='g',cmap='Set3')
plt.show()

def y_pred_svc():
  print(accuracy_score(y_test, y_pred_svc))

print(precision_score(y_test, y_pred_svc))

print(recall_score(y_test, y_pred_svc))

y_score = svc.decision_function(X_test)
FPR, TPR, _ = roc_curve(y_test, y_score)
ROC_AUC = auc(FPR, TPR)
print (ROC_AUC)
plt.figure(figsize =[11,9])
plt.plot(FPR, TPR, label= 'ROC curve(area = %0.2f)'%ROC_AUC, linewidth= 4)
plt.plot([0,1],[0,1], 'k--', linewidth = 4)
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate', fontsize = 18)
plt.ylabel('True Positive Rate', fontsize = 18)
plt.title('Receiver operating characteristic example', fontsize= 18)
plt.show()

def y_score():
  roc_auc_score(y_test, y_score)